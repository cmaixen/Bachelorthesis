\section{Latent Semantic Analysis (LSA) Experiment}\label{Latent Semantic Analysis Experiment (LSA) Experiment}

We stellen nu een proefopstelling op en we gaan het de vector space methode bij text mining toepassen op een echt voorbeeld.

\subsection{Proefopstelling}\label{Proefopstelling}
Als eerste verkrijgen we onze trainingsset door de polarity v2 dataset (website: \url{http://www.cs.cornell.edu/People/pabo/movie-review-data}) te downloaden. Deze dataset bevat positieve en negatieve recensies van imdb. We hebben te maken met supervised learning, want we weten welke recensies positief en welke negatief zijn. Het doel van het experiment is door middel van de geziene technieken zoals de vector space methode met latent semantic analysis en term weighting een inzicht te krijgen in de dataset en we proberen gelijkaardige recensies te groeperen. Tenslotte onderzoeken we de hypothese, waarbij we zeggen hoe meer features we hebben voor een document, hoe groter de nauwkeurigheid bij de classificatie.


\subsection{Werkwijze}\label{Werkwijze}

De werkwijze verloopt als volgt:
Eerst passen we document pre-processing toe. We halen alle stopwoorden en leestekens uit de dataset. Vervolgens stellen we een document-term matrix op. Dan optimaliseren we deze matrix voor classificatie door de matrix om te vormen naar een tf-idf matrix. Dit is de techniek waarbij we iedere frequentie $f_{ij}$ van een woord $w_{i}$ vervangen door de tf-idf score van het woord. Daaropvolgend reduceren we de dimensie van onze tf-idf matrix naar twee door de latent semantic methode toe te passen. Iedere recensie wordt na de reductie voorgesteld door middel van twee features. 
De recensies plotten we dan met elke recensie als een punt met een andere kleur voor positieve en negatieve recensies.
Ten slotte nemen we terug onze tf-idf matrix en reduceren het naar door een bepaald aantal features bijvoorbeeld 10, 50, 100, 500. En we kijken of onze hypothese geld waarbij we betere classificatie resultaten krijgen bij meer features.

\subsection{Resultaten}\label{Resultaten}

Als resultaat zien we dat het invoeren van term weighting zoals de tf-idf matrix echt wel nut heeft voor dat we de latent semantic methode toepassen.
Als we de twee plots vergelijken, de ene zonder term weighting dan andere met term weighting, zien we duidelijk dat we bij diegene met term weighting duidelijk twee groepen kunnen onderscheiden.

\begin{figure}%
    \centering
    \subfloat[LSA zonder term weighting]{{\includegraphics[width=5cm]{experiment_1} }}%
    \qquad
    \subfloat[LSA met term weighting]{{\includegraphics[width=5cm]{experiment_2} }}%
    \caption{Effect van term weighting voor LSA}%
    \label{fig:example}%
\end{figure}
%
Tenslotte kunnen we ook onze hypothese bevestigen. We zien dat de hoeveelheid aan features, de nauwkeurigheid van de classificatie be\"invloed. Onderstaande afbeelding geeft deze relatie weer. De x-waarde stelt het aantal gelijkaardige recensies dat men opvraagt voor. De y-waarde geeft aan hoeveel er gemiddeld effectief juist geclassificeerd zijn. Belangrijk om te weten is dat de dataset voor de helft uit positieve recensies bestaat en voor de helft uit negatieve. We trachten dus bij de classificatie een gemiddeld percentage van 50 percent te halen en we zien dat op onderstaand voorbeeld de lijn van 500 features hier het beste in slaagt.


\begin{center}
  \includegraphics[width=10cm]{experiment_3}
  \captionof{figure}{Nauwkeurigheid van de classificatie bij een verschillend aantal features}
\end{center}